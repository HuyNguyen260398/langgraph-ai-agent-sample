{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6273026b",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m48 packages\u001b[0m \u001b[2min 0.77ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m47 packages\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "uv add python-dotenv langgraph langsmith \"langchain[anthropic]\" langchain-tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "memory = InMemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e299fac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': \"What's a 'node' in LangGraph?\",\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'url': 'https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns/langgraph',\n",
       "   'title': 'LangGraph | Arize Phoenix',\n",
       "   'content': '*   [Agent Cookbooks](https://arize.com/docs/phoenix/cookbook/agent-cookbooks) *   [Agent Demos](https://arize.com/docs/phoenix/cookbook/agent-demos) *   [Agent Workflow Patterns](https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns) *   [AutoGen](https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns/autogen) *   [CrewAI](https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns/crewai) *   [Google GenAI SDK (Manual Orchestration)](https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns/google-genai-sdk-manual-orchestration) *   [OpenAI Agents](https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns/openai-agents) *   [LangGraph](https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns/langgraph) *   [Smolagents](https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns/smolagents) *   [Generating Synthetic Datasets for LLM Evaluators & Agents](https://arize.com/docs/phoenix/cookbook/tracing/generating-synthetic-datasets-for-llm-evaluators-and-agents) *   [Product Recommendation Agent: Google Agent Engine & LangGraph](https://arize.com/docs/phoenix/cookbook/tracing/product-recommendation-agent-google-agent-engine-and-langgraph) *   [Creating a Custom LLM Evaluator with a Benchmark Dataset](https://arize.com/docs/phoenix/cookbook/human-in-the-loop-workflows-annotations/creating-a-custom-llm-evaluator-with-a-benchmark-dataset) *   [Evaluate a Talk-to-your-Data Agent](https://arize.com/docs/phoenix/cookbook/evaluation/evaluate-an-agent) *    [Core LangGraph Concepts](https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns/langgraph#core-langgraph-concepts) *   [Design Considerations & Limitations](https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns/langgraph#design-considerations-and-limitations) *   [Patterns](https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns/langgraph#patterns) *   [Prompt Chaining](https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns/langgraph#prompt-chaining) *   [Parallelization](https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns/langgraph#parallelization) *   [Router](https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns/langgraph#router) *   [Evaluator–Optimizer Loop](https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns/langgraph#evaluator-optimizer-loop) *   [Orchestrator–Worker](https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns/langgraph#orchestrator-worker) [Edit](https://github.com/Arize-ai/phoenix/blob/docs/docs/section-cookbooks/agent-workflow-patterns/langgraph.md) 1.   [Agent Workflow Patterns](https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns) ### [](https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns/langgraph#core-langgraph-concepts) #### [](https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns/langgraph#state) #### [](https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns/langgraph#nodes) #### [](https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns/langgraph#edges) #### [](https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns/langgraph#conditional-routing) #### [](https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns/langgraph#send-api) #### [](https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns/langgraph#agent-supervision) #### [](https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns/langgraph#checkpointing-and-persistence) ### [](https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns/langgraph#design-considerations-and-limitations) [](https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns/langgraph#patterns) ### [](https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns/langgraph#prompt-chaining) ### [](https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns/langgraph#parallelization) ### [](https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns/langgraph#router) ### [](https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns/langgraph#evaluator-optimizer-loop) ### [](https://arize.com/docs/phoenix/cookbook/agent-workflow-patterns/langgraph#orchestrator-worker)',\n",
       "   'score': 0.68571854,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://medium.com/@cplog/introduction-to-langgraph-a-beginners-guide-14f9be027141',\n",
       "   'title': \"Introduction to LangGraph: A Beginner's Guide - Medium\",\n",
       "   'content': '* **Stateful Graph:** LangGraph revolves around the concept of a stateful graph, where each node in the graph represents a step in your computation, and the graph maintains a state that is passed around and updated as the computation progresses. LangGraph supports conditional edges, allowing you to dynamically determine the next node to execute based on the current state of the graph. We add our nodes to the graph and define the flow using edges and conditional edges. workflow.add_node(\"classify_input\", classify_input_node)workflow.add_node(\"handle_greeting\", handle_greeting_node)workflow.add_node(\"handle_search\", handle_search_node)def decide_next_node(state): return \"handle_greeting\" if state.get(\\'classification\\') == \"greeting\" else \"handle_search\"workflow.add_conditional_edges( \"classify_input\", decide_next_node, { \"handle_greeting\": \"handle_greeting\", \"handle_search\": \"handle_search\" }) Remember to pay attention to state management, conditional edges, and ensuring there are no dead-end nodes in your graph.',\n",
       "   'score': 0.6356076,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 0.99,\n",
       " 'request_id': 'a9164c33-f114-461e-8b5f-6d27b66bdcc6'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool]\n",
    "tool.invoke(\"What's a 'node' in LangGraph?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ada70a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = init_chat_model(\"claude-sonnet-4-5-20250929\")\n",
    "\n",
    "# Modification: tell the LLM which tools it can call\n",
    "llm_with_tools = llm.bind_tools(tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc85111c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fa8a979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x234adfc8950>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever\n",
    "# the node is used.\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "# graph_builder.add_edge(START, \"chatbot\")\n",
    "# graph_builder.add_edge(\"chatbot\", END)\n",
    "# graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37123ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x234adfc8950>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "\n",
    "class BasicToolNode:\n",
    "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
    "\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs: dict):\n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No message found in input\")\n",
    "        outputs = []\n",
    "        for tool_call in message.tool_calls:\n",
    "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
    "                tool_call[\"args\"]\n",
    "            )\n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(tool_result),\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "        return {\"messages\": outputs}\n",
    "\n",
    "\n",
    "tool_node = BasicToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_tools(\n",
    "    state: State,\n",
    "):\n",
    "    \"\"\"\n",
    "    Use in the conditional_edge to route to the ToolNode if the last message\n",
    "    has tool calls. Otherwise, route to the end.\n",
    "    \"\"\"\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif messages := state.get(\"messages\", []):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "\n",
    "# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"END\" if\n",
    "# it is fine directly responding. This conditional routing defines the main agent loop.\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    route_tools,\n",
    "    # The following dictionary lets you tell the graph to interpret the condition's outputs as a specific node\n",
    "    # It defaults to the identity function, but if you\n",
    "    # want to use a node named something else apart from \"tools\",\n",
    "    # You can update the value of the dictionary to something else\n",
    "    # e.g., \"tools\": \"my_tools\"\n",
    "    {\"tools\": \"tools\", END: END},\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3286fd4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48b8ea19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What do you know about LangGraph?\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Checkpointer requires one or more of the following 'configurable' keys: thread_id, checkpoint_ns, checkpoint_id",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     12\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     \u001b[43mstream_graph_updates\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# fallback if input() is not available\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mstream_graph_updates\u001b[39m\u001b[34m(user_input)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstream_graph_updates\u001b[39m(user_input: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Workspace\\langgraph-ai-agent-sample\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2551\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2540\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2541\u001b[39m     \u001b[38;5;66;03m# assign defaults\u001b[39;00m\n\u001b[32m   2542\u001b[39m     (\n\u001b[32m   2543\u001b[39m         stream_modes,\n\u001b[32m   2544\u001b[39m         output_keys,\n\u001b[32m   2545\u001b[39m         interrupt_before_,\n\u001b[32m   2546\u001b[39m         interrupt_after_,\n\u001b[32m   2547\u001b[39m         checkpointer,\n\u001b[32m   2548\u001b[39m         store,\n\u001b[32m   2549\u001b[39m         cache,\n\u001b[32m   2550\u001b[39m         durability_,\n\u001b[32m-> \u001b[39m\u001b[32m2551\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_defaults\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2552\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2553\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2554\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2555\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2556\u001b[39m \u001b[43m        \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2557\u001b[39m \u001b[43m        \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2558\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2559\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2560\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m checkpointer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m durability \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Workspace\\langgraph-ai-agent-sample\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2421\u001b[39m, in \u001b[36mPregel._defaults\u001b[39m\u001b[34m(self, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability)\u001b[39m\n\u001b[32m   2420\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m checkpointer \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config.get(CONF):\n\u001b[32m-> \u001b[39m\u001b[32m2421\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2422\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCheckpointer requires one or more of the following \u001b[39m\u001b[33m'\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2423\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mkeys: thread_id, checkpoint_ns, checkpoint_id\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2424\u001b[39m     )\n\u001b[32m   2425\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m CONFIG_KEY_RUNTIME \u001b[38;5;129;01min\u001b[39;00m config.get(CONF, {}):\n",
      "\u001b[31mValueError\u001b[39m: Checkpointer requires one or more of the following 'configurable' keys: thread_id, checkpoint_ns, checkpoint_id",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m user_input = \u001b[33m\"\u001b[39m\u001b[33mWhat do you know about LangGraph?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mUser: \u001b[39m\u001b[33m\"\u001b[39m + user_input)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mstream_graph_updates\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mstream_graph_updates\u001b[39m\u001b[34m(user_input)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstream_graph_updates\u001b[39m(user_input: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAssistant:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Workspace\\langgraph-ai-agent-sample\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2551\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2534\u001b[39m run_manager = callback_manager.on_chain_start(\n\u001b[32m   2535\u001b[39m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2536\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   2537\u001b[39m     name=config.get(\u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.get_name()),\n\u001b[32m   2538\u001b[39m     run_id=config.get(\u001b[33m\"\u001b[39m\u001b[33mrun_id\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   2539\u001b[39m )\n\u001b[32m   2540\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2541\u001b[39m     \u001b[38;5;66;03m# assign defaults\u001b[39;00m\n\u001b[32m   2542\u001b[39m     (\n\u001b[32m   2543\u001b[39m         stream_modes,\n\u001b[32m   2544\u001b[39m         output_keys,\n\u001b[32m   2545\u001b[39m         interrupt_before_,\n\u001b[32m   2546\u001b[39m         interrupt_after_,\n\u001b[32m   2547\u001b[39m         checkpointer,\n\u001b[32m   2548\u001b[39m         store,\n\u001b[32m   2549\u001b[39m         cache,\n\u001b[32m   2550\u001b[39m         durability_,\n\u001b[32m-> \u001b[39m\u001b[32m2551\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_defaults\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2552\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2553\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2554\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2555\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2556\u001b[39m \u001b[43m        \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2557\u001b[39m \u001b[43m        \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2558\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2559\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2560\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m checkpointer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m durability \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2561\u001b[39m         warnings.warn(\n\u001b[32m   2562\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m`durability` has no effect when no checkpointer is present.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2563\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Workspace\\langgraph-ai-agent-sample\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2421\u001b[39m, in \u001b[36mPregel._defaults\u001b[39m\u001b[34m(self, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability)\u001b[39m\n\u001b[32m   2419\u001b[39m     checkpointer = \u001b[38;5;28mself\u001b[39m.checkpointer\n\u001b[32m   2420\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m checkpointer \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config.get(CONF):\n\u001b[32m-> \u001b[39m\u001b[32m2421\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2422\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCheckpointer requires one or more of the following \u001b[39m\u001b[33m'\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2423\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mkeys: thread_id, checkpoint_ns, checkpoint_id\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2424\u001b[39m     )\n\u001b[32m   2425\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m CONFIG_KEY_RUNTIME \u001b[38;5;129;01min\u001b[39;00m config.get(CONF, {}):\n\u001b[32m   2426\u001b[39m     store: BaseStore | \u001b[38;5;28;01mNone\u001b[39;00m = config[CONF][CONFIG_KEY_RUNTIME].store\n",
      "\u001b[31mValueError\u001b[39m: Checkpointer requires one or more of the following 'configurable' keys: thread_id, checkpoint_ns, checkpoint_id"
     ]
    }
   ],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6a4ff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi there! My name is Will.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Will! Nice to meet you! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Hi there! My name is Will.\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Remember my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Yes, I remember! Your name is Will. What can I help you with today?\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Remember my name?\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Remember my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I don't have any previous memory of your name or our past conversations. Each conversation I have starts fresh without access to previous interactions.\n",
      "\n",
      "If you'd like to tell me your name, I'd be happy to use it during our current conversation! However, I won't be able to remember it in future conversations.\n"
     ]
    }
   ],
   "source": [
    "# The only difference is we change the `thread_id` here to \"2\" instead of \"1\"\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    {\"configurable\": {\"thread_id\": \"2\"}},\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Hi there! My name is Will.', additional_kwargs={}, response_metadata={}, id='9eb03ed0-abbe-4cc1-9299-aad551fd2de3'), AIMessage(content='Hello Will! Nice to meet you! How can I help you today?', additional_kwargs={}, response_metadata={'id': 'msg_019YhNvhNB4dCYYtCfVqoRUF', 'model': 'claude-sonnet-4-5-20250929', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 2308, 'output_tokens': 18, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-sonnet-4-5-20250929', 'model_provider': 'anthropic'}, id='lc_run--707835c1-3d86-4886-b07b-31af73d1ac78-0', usage_metadata={'input_tokens': 2308, 'output_tokens': 18, 'total_tokens': 2326, 'input_token_details': {'cache_creation': 0, 'cache_read': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}}), HumanMessage(content='Remember my name?', additional_kwargs={}, response_metadata={}, id='7209726e-c30d-41a1-9a67-564c600709c7'), AIMessage(content='Yes, I remember! Your name is Will. What can I help you with today?', additional_kwargs={}, response_metadata={'id': 'msg_01Jp9rBptTispq4iQV3cxJdf', 'model': 'claude-sonnet-4-5-20250929', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 2333, 'output_tokens': 21, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-sonnet-4-5-20250929', 'model_provider': 'anthropic'}, id='lc_run--4210898e-ff64-48d9-a4e0-075ee6dc2ab5-0', usage_metadata={'input_tokens': 2333, 'output_tokens': 21, 'total_tokens': 2354, 'input_token_details': {'cache_creation': 0, 'cache_read': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0af9dc-e2dc-645b-8004-1bfadd898379'}}, metadata={'source': 'loop', 'step': 4, 'parents': {}}, created_at='2025-10-22T23:21:15.231753+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0af9dc-c949-692d-8003-82208a8a2af5'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
