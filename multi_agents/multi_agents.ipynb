{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61997a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Annotated, TypedDict, List, Literal\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e8a7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "llm = init_chat_model(\"claude-sonnet-4-5-20250929\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5951fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(MessagesState):\n",
    "    next_agent: str # which agent to call next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bed375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create simple tools\n",
    "@tool\n",
    "def search_web(query: str) -> str:\n",
    "    \"\"\"Search the web using Tavily Search.\"\"\"\n",
    "    search = TavilySearchResults(max_results=3)\n",
    "    results = search.invoke(query)\n",
    "    return str(results)\n",
    "\n",
    "@tool\n",
    "def write_summary(content: str) -> str:\n",
    "    \"\"\"Write a brief summary of the given content.\"\"\"\n",
    "    summary = f\"This is a brief summary of the content: {content[:75]}...\"\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80203d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define agent functions (simple approach)\n",
    "def researcher_agent(state: AgentState):\n",
    "    \"\"\"Researcher agent that searches the web for information.\"\"\"\n",
    "\n",
    "    messages = state['messages']\n",
    "\n",
    "    # add system message for context\n",
    "    system_msg = SystemMessage(content=\"You are a researcher agent. Your task is to use search_web tool to gather information on a given topic.\")\n",
    "\n",
    "    # call llm with tools\n",
    "    researcher_llm = llm.bind_tools([search_web])\n",
    "    response = researcher_llm.invoke([system_msg] + messages)\n",
    "\n",
    "    # return the response and route to writer agent\n",
    "    return {\n",
    "        'messages': [response],\n",
    "        'next_agent': 'writer'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ea2136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writer_agent(state: AgentState):\n",
    "    \"\"\"Writer agent that summarizes the researched information.\"\"\"\n",
    "\n",
    "    messages = state['messages']\n",
    "\n",
    "    # add system message for context\n",
    "    system_msg = SystemMessage(content=\"You are a writer agent. Your task is to use write_summary tool to summarize the researched information.\")\n",
    "\n",
    "    # call llm with tools\n",
    "    writer_llm = llm.bind_tools([write_summary])\n",
    "    response = writer_llm.invoke([system_msg] + messages)\n",
    "\n",
    "    # return the response and end the process\n",
    "    return {\n",
    "        'messages': [response],\n",
    "        'next_agent': 'end'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e220e101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool executor node\n",
    "def execute_tools(state: AgentState):\n",
    "    \"\"\"Execute any pending tool calls\"\"\"\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    # check if there are tool calls to execute\n",
    "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        # create tool node and execute tools\n",
    "        tool_node = ToolNode(tools=[search_web, write_summary])\n",
    "        response = tool_node.invoke(state)\n",
    "        return response\n",
    "\n",
    "    # no tool calls, return state as is\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build graph with proper tool execution flow\n",
    "def should_continue(state: AgentState):\n",
    "    \"\"\"Router function to decide whether to execute tools or continue to next agent.\"\"\"\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # if there are tool calls, route to tools\n",
    "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    \n",
    "    # otherwise, check next_agent\n",
    "    next_agent = state.get('next_agent', 'end')\n",
    "    if next_agent == 'end':\n",
    "        return END\n",
    "    return next_agent\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# add nodes\n",
    "workflow.add_node('researcher', researcher_agent)\n",
    "workflow.add_node('writer', writer_agent)\n",
    "workflow.add_node('tools', execute_tools)\n",
    "\n",
    "# define flow with conditional routing\n",
    "workflow.set_entry_point('researcher')\n",
    "\n",
    "# after researcher, check if tools need to be executed\n",
    "workflow.add_conditional_edges(\n",
    "    'researcher',\n",
    "    should_continue,\n",
    "    {\n",
    "        'tools': 'tools',\n",
    "        'writer': 'writer',\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "# after tools are executed, route back to appropriate agent\n",
    "workflow.add_edge('tools', 'writer')\n",
    "\n",
    "# after writer, check if tools need to be executed or end\n",
    "workflow.add_conditional_edges(\n",
    "    'writer',\n",
    "    should_continue,\n",
    "    {\n",
    "        'tools': 'tools',\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "final_workflow = workflow.compile()\n",
    "final_workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = final_workflow.invoke({'messages': 'Research about the useace of agentic ai in business'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the final response\n",
    "for message in response['messages']:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Type: {type(message).__name__}\")\n",
    "    if hasattr(message, 'content'):\n",
    "        print(f\"Content: {message.content}\")\n",
    "    if hasattr(message, 'tool_calls') and message.tool_calls:\n",
    "        print(f\"Tool Calls: {len(message.tool_calls)}\")\n",
    "        for tool_call in message.tool_calls:\n",
    "            print(f\"  - {tool_call['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4550702",
   "metadata": {},
   "source": [
    "### Supervisor Multi AI Agent Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List, Literal, Dict, Any\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "llm = init_chat_model(\"claude-sonnet-4-5-20250929\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# State Definition\n",
    "# ===================================\n",
    "\n",
    "# ===================================\n",
    "# State Definition\n",
    "# ===================================\n",
    "\n",
    "class SupervisorState(MessagesState):\n",
    "    \"\"\"State for the multi-agent system\"\"\"\n",
    "    next_agent: str = \"\"\n",
    "    research_data: str = \"\"\n",
    "    analysis: str = \"\"\n",
    "    final_report: str = \"\"\n",
    "    task_complete: bool = False\n",
    "    current_task: str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# Supervisor\n",
    "# ===================================\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "def create_supervisor_chain():\n",
    "    \"\"\"Creates the supervisor decision chain\"\"\"\n",
    "    \n",
    "    supervisor_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are a supervisor managing a team of agents:\n",
    "        \n",
    "1. Researcher - Gathers information and data\n",
    "2. Analyst - Analyzes data and provides insights  \n",
    "3. Writer - Creates reports and summaries\n",
    "\n",
    "Based on the current state and conversation, decide which agent should work next.\n",
    "If the task is complete, respond with 'DONE'.\n",
    "\n",
    "Current state:\n",
    "- Has research data: {has_research}\n",
    "- Has analysis: {has_analysis}\n",
    "- Has report: {has_report}\n",
    "\n",
    "Respond with ONLY the agent name (researcher/analyst/writer) or 'DONE'.\n",
    "\"\"\"),\n",
    "        (\"human\", \"{task}\")\n",
    "    ])\n",
    "    \n",
    "    return supervisor_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervisor_agent(state: SupervisorState) -> Dict:\n",
    "    \"\"\"Supervisor decides next agent\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    task = messages[-1].content if messages else \"No task\"\n",
    "    \n",
    "    # Check what's been completed\n",
    "    has_research = bool(state.get(\"research_data\", \"\"))\n",
    "    has_analysis = bool(state.get(\"analysis\", \"\"))\n",
    "    has_report = bool(state.get(\"final_report\", \"\"))\n",
    "    \n",
    "    # Get LLM decision\n",
    "    chain = create_supervisor_chain()\n",
    "    decision = chain.invoke({\n",
    "        \"task\": task,\n",
    "        \"has_research\": has_research,\n",
    "        \"has_analysis\": has_analysis,\n",
    "        \"has_report\": has_report\n",
    "    })\n",
    "    \n",
    "    # Parse decision\n",
    "    decision_text = decision.content.strip().lower()\n",
    "    print(decision_text)\n",
    "    \n",
    "    # Determine next agent\n",
    "    if \"done\" in decision_text or has_report:\n",
    "        next_agent = \"end\"\n",
    "        supervisor_msg = \"âœ… Supervisor: All tasks complete! Great work team.\"\n",
    "    elif \"researcher\" in decision_text or not has_research:\n",
    "        next_agent = \"researcher\"\n",
    "        supervisor_msg = \"ðŸ“‹ Supervisor: Let's start with research. Assigning to Researcher...\"\n",
    "    elif \"analyst\" in decision_text or (has_research and not has_analysis):\n",
    "        next_agent = \"analyst\"\n",
    "        supervisor_msg = \"ðŸ“‹ Supervisor: Research done. Time for analysis. Assigning to Analyst...\"\n",
    "    elif \"writer\" in decision_text or (has_analysis and not has_report):\n",
    "        next_agent = \"writer\"\n",
    "        supervisor_msg = \"ðŸ“‹ Supervisor: Analysis complete. Let's create the report. Assigning to Writer...\"\n",
    "    else:\n",
    "        next_agent = \"end\"\n",
    "        supervisor_msg = \"âœ… Supervisor: Task seems complete.\"\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=supervisor_msg)],\n",
    "        \"next_agent\": next_agent,\n",
    "        \"current_task\": task\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# Agent 1: Researcher\n",
    "# ===================================\n",
    "\n",
    "def researcher_agent(state: SupervisorState) -> Dict:\n",
    "    \"\"\"Researcher to gather information\"\"\"\n",
    "    \n",
    "    task = state.get(\"current_task\", \"research topic\")\n",
    "    \n",
    "    # Create research prompt\n",
    "    research_prompt = f\"\"\"As a research specialist, provide comprehensive information about: {task}\n",
    "\n",
    "    Include:\n",
    "    1. Key facts and background\n",
    "    2. Current trends or developments\n",
    "    3. Important statistics or data points\n",
    "    4. Notable examples or case studies\n",
    "    \n",
    "    Be concise but thorough.\"\"\"\n",
    "    \n",
    "    # Get research from LLM\n",
    "    research_response = llm.invoke([HumanMessage(content=research_prompt)])\n",
    "    research_data = research_response.content\n",
    "    \n",
    "    # Create agent message\n",
    "    agent_message = f\"ðŸ” Researcher: I've completed the research on '{task}'.\\n\\nKey findings:\\n{research_data[:500]}...\"\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=agent_message)],\n",
    "        \"research_data\": research_data,\n",
    "        \"next_agent\": \"supervisor\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# Agent 2: Analyst\n",
    "# ===================================\n",
    "\n",
    "def analyst_agent(state: SupervisorState) -> Dict:\n",
    "    \"\"\"Analyst uses Groq to analyze the research\"\"\"\n",
    "    \n",
    "    research_data = state.get(\"research_data\", \"\")\n",
    "    task = state.get(\"current_task\", \"\")\n",
    "    \n",
    "    # Create analysis prompt\n",
    "    analysis_prompt = f\"\"\"As a data analyst, analyze this research data and provide insights:\n",
    "\n",
    "Research Data:\n",
    "{research_data}\n",
    "\n",
    "Provide:\n",
    "1. Key insights and patterns\n",
    "2. Strategic implications\n",
    "3. Risks and opportunities\n",
    "4. Recommendations\n",
    "\n",
    "Focus on actionable insights related to: {task}\"\"\"\n",
    "    \n",
    "    # Get analysis from LLM\n",
    "    analysis_response = llm.invoke([HumanMessage(content=analysis_prompt)])\n",
    "    analysis = analysis_response.content\n",
    "    \n",
    "    # Create agent message\n",
    "    agent_message = f\"ðŸ“Š Analyst: I've completed the analysis.\\n\\nTop insights:\\n{analysis[:400]}...\"\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=agent_message)],\n",
    "        \"analysis\": analysis,\n",
    "        \"next_agent\": \"supervisor\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# Agent 3: Writer\n",
    "# ===================================\n",
    "\n",
    "def writer_agent(state: SupervisorState) -> Dict:\n",
    "    \"\"\"Writer uses Groq to create final report\"\"\"\n",
    "    \n",
    "    research_data = state.get(\"research_data\", \"\")\n",
    "    analysis = state.get(\"analysis\", \"\")\n",
    "    task = state.get(\"current_task\", \"\")\n",
    "    \n",
    "    # Create writing prompt\n",
    "    writing_prompt = f\"\"\"As a professional writer, create an executive report based on:\n",
    "\n",
    "Task: {task}\n",
    "\n",
    "Research Findings:\n",
    "{research_data[:1000]}\n",
    "\n",
    "Analysis:\n",
    "{analysis[:1000]}\n",
    "\n",
    "Create a well-structured report with:\n",
    "1. Executive Summary\n",
    "2. Key Findings  \n",
    "3. Analysis & Insights\n",
    "4. Recommendations\n",
    "5. Conclusion\n",
    "\n",
    "Keep it professional and concise.\"\"\"\n",
    "    \n",
    "    # Get report from LLM\n",
    "    report_response = llm.invoke([HumanMessage(content=writing_prompt)])\n",
    "    report = report_response.content\n",
    "    \n",
    "    # Create final formatted report\n",
    "    final_report = f\"\"\"\n",
    "ðŸ“„ FINAL REPORT\n",
    "{'='*50}\n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n",
    "Topic: {task}\n",
    "{'='*50}\n",
    "\n",
    "{report}\n",
    "\n",
    "{'='*50}\n",
    "Report compiled by Multi-Agent AI System powered by Groq\n",
    "\"\"\"\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=f\"âœï¸ Writer: Report complete! See below for the full document.\")],\n",
    "        \"final_report\": final_report,\n",
    "        \"next_agent\": \"supervisor\",\n",
    "        \"task_complete\": True\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# Router Function\n",
    "# ===================================\n",
    "\n",
    "def router(state: SupervisorState) -> Literal[\"supervisor\", \"researcher\", \"analyst\", \"writer\", \"__end__\"]:\n",
    "    \"\"\"Routes to next agent based on state\"\"\"\n",
    "    \n",
    "    next_agent = state.get(\"next_agent\", \"supervisor\")\n",
    "    \n",
    "    if next_agent == \"end\" or state.get(\"task_complete\", False):\n",
    "        return END\n",
    "        \n",
    "    if next_agent in [\"supervisor\", \"researcher\", \"analyst\", \"writer\"]:\n",
    "        return next_agent\n",
    "        \n",
    "    return \"supervisor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create workflow\n",
    "workflow = StateGraph(SupervisorState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"supervisor\", supervisor_agent)\n",
    "workflow.add_node(\"researcher\", researcher_agent)\n",
    "workflow.add_node(\"analyst\", analyst_agent)\n",
    "workflow.add_node(\"writer\", writer_agent)\n",
    "\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "# Add routing\n",
    "for node in [\"supervisor\", \"researcher\", \"analyst\", \"writer\"]:\n",
    "    workflow.add_conditional_edges(\n",
    "        node,\n",
    "        router,\n",
    "        {\n",
    "            \"supervisor\": \"supervisor\",\n",
    "            \"researcher\": \"researcher\",\n",
    "            \"analyst\": \"analyst\",\n",
    "            \"writer\": \"writer\",\n",
    "            END: END\n",
    "        }\n",
    "    )\n",
    "\n",
    "graph=workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke(HumanMessage(content=\"What are the benefits and risks of AI in healthcare?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response['final_report']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
