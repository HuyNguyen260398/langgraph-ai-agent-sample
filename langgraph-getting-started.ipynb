{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71d0c7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = init_chat_model(\"claude-sonnet-4-5-20250929\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d1ee648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from langchain_core.messages import AnyMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efc841d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bc1e161",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the State using TypedDict\n",
    "class ChatbotStateTD(TypedDict):\n",
    "    messages: List[AnyMessage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2341192e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial State\n",
    "initial_state_typeddict = ChatbotStateTD(messages=[])\n",
    "type(initial_state_typeddict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e2471c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial State (TypedDict): {'messages': []}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Initial State (TypedDict): {initial_state_typeddict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58e691aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial State (TypedDict): {'messages': []}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initial State with dictionary\n",
    "initial_state_typeddict = ChatbotStateTD({\"messages\": []})\n",
    "\n",
    "print(f\"Initial State (TypedDict): {initial_state_typeddict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96f3434f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_state_typeddict_1={'messages': True}\n",
      "initial_state_typeddict_2={'messages': ['hello']}\n"
     ]
    }
   ],
   "source": [
    "# Initial State with wrong types\n",
    "initial_state_typeddict_1 = ChatbotStateTD({\"messages\": True})\n",
    "initial_state_typeddict_2 = ChatbotStateTD({\"messages\": [\"hello\"]})\n",
    "\n",
    "print(f\"{initial_state_typeddict_1=}\\n{initial_state_typeddict_2=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the State using TypedDict\n",
    "class ChatbotStateBM(BaseModel):\n",
    "    messages: List[AnyMessage] = Field(default_factory=list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatbotStateBM(messages=[])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial State\n",
    "initial_state_pydantic = ChatbotStateBM()\n",
    "initial_state_pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial State (Pydantic): messages=[]\n",
      "Initial State (Pydantic): {'messages': []}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Initial State (Pydantic): {initial_state_pydantic}\")\n",
    "print(f\"Initial State (Pydantic): {initial_state_pydantic.model_dump()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatbotStateBM(messages=[HumanMessage(content='Hello!', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Initial State with non-default value\n",
    "initial_state_pydantic = ChatbotStateBM(messages=[HumanMessage(\"Hello!\")])\n",
    "initial_state_pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ChatbotStateBM\nmessages\n  Input should be a valid list [type=list_type, input_value='Hello!', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/list_type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Initial State with wrong type\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m initial_state_pydantic = \u001b[43mChatbotStateBM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHello!\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Workspace\\langgraph-ai-agent-sample\\.venv\\Lib\\site-packages\\pydantic\\main.py:250\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    249\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    252\u001b[39m     warnings.warn(\n\u001b[32m    253\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    254\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    256\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    257\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for ChatbotStateBM\nmessages\n  Input should be a valid list [type=list_type, input_value='Hello!', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/list_type"
     ]
    }
   ],
   "source": [
    "# Initial State with wrong type\n",
    "initial_state_pydantic = ChatbotStateBM(messages=\"Hello!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define graph with multiple states (input, internal, and output)\n",
    "class InputState(TypedDict):\n",
    "    user_input: str\n",
    "\n",
    "class OutputState(TypedDict):\n",
    "    graph_output: str\n",
    "\n",
    "class InternalState(TypedDict):\n",
    "    internal_var: str\n",
    "    user_input: str\n",
    "    graph_output: str\n",
    "\n",
    "graph = StateGraph(InternalState, input_schema=InputState, output_schema=OutputState)\n",
    "\n",
    "#### We can also define private input and output state node states (images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default reducer function\n",
    "class State(TypedDict):\n",
    "    foo: int\n",
    "    bar: str\n",
    "    baz: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cutom reducer function\n",
    "from typing import Annotated\n",
    "from operator import add\n",
    "\n",
    "def custom_reducer(old_value, new_value) -> float:\n",
    "  return (old_value + new_value)/2\n",
    "\n",
    "def increment(old_value, new_value) -> int:\n",
    "  return old_value + 1\n",
    "\n",
    "class State(TypedDict):\n",
    "    foo: Annotated[float, custom_reducer]\n",
    "    baz: Annotated[int, increment] # Count nbr of updates\n",
    "    bar: Annotated[list[str], add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define state\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# define chatbot 1 node\n",
    "def chatbot1(state: State) -> State:\n",
    "    llm_response = \"Hello from the chatbot1!\"\n",
    "    return {\"messages\": [llm_response]}\n",
    "\n",
    "# define chatbot 2 node\n",
    "def chatbot2(state: State) -> State:\n",
    "    llm_response = \"Hello from the chatbot2!\"\n",
    "    return {\"messages\": [llm_response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x279f7995430>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a graph builder\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# Add node\n",
    "graph_builder.add_node(\"chatbot1\", chatbot1)\n",
    "\n",
    "# We can also add caching to an expensive node\n",
    "graph_builder.add_node(\"chatbot2\", chatbot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Graph must have an entrypoint: add at least one edge from START to another node",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mgraph_builder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Workspace\\langgraph-ai-agent-sample\\.venv\\Lib\\site-packages\\langgraph\\graph\\state.py:836\u001b[39m, in \u001b[36mStateGraph.compile\u001b[39m\u001b[34m(self, checkpointer, cache, store, interrupt_before, interrupt_after, debug, name)\u001b[39m\n\u001b[32m    833\u001b[39m interrupt_after = interrupt_after \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m    835\u001b[39m \u001b[38;5;66;03m# validate the graph\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m836\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    840\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[38;5;66;03m# prepare output channels\u001b[39;00m\n\u001b[32m    845\u001b[39m output_channels = (\n\u001b[32m    846\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m__root__\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    847\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.schemas[\u001b[38;5;28mself\u001b[39m.output_schema]) == \u001b[32m1\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    853\u001b[39m     ]\n\u001b[32m    854\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Workspace\\langgraph-ai-agent-sample\\.venv\\Lib\\site-packages\\langgraph\\graph\\state.py:766\u001b[39m, in \u001b[36mStateGraph.validate\u001b[39m\u001b[34m(self, interrupt)\u001b[39m\n\u001b[32m    763\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound edge starting at unknown node \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    765\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m START \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m all_sources:\n\u001b[32m--> \u001b[39m\u001b[32m766\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    767\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mGraph must have an entrypoint: add at least one edge from START to another node\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    768\u001b[39m     )\n\u001b[32m    770\u001b[39m \u001b[38;5;66;03m# assemble targets\u001b[39;00m\n\u001b[32m    771\u001b[39m all_targets = {end \u001b[38;5;28;01mfor\u001b[39;00m _, end \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._all_edges}\n",
      "\u001b[31mValueError\u001b[39m: Graph must have an entrypoint: add at least one edge from START to another node"
     ]
    }
   ],
   "source": [
    "\n",
    "graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x279f7995430>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# define normal (direct) edge\n",
    "graph_builder.add_edge(START, \"chatbot1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x279f7995430>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define conditional edge\n",
    "def routing_function(state: State) -> str:\n",
    "    if len(state[\"messages\"]) > 1000:\n",
    "        return \"chatbot2\"\n",
    "    return \"chatbot1\"\n",
    "\n",
    "graph_builder.add_conditional_edges(START, routing_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x279f7995430>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# define conditional edge with path mapping\n",
    "def use_chatbot2(state: State) -> str:\n",
    "    if len(state[\"messages\"]) > 1000:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "graph_builder.add_conditional_edges(START, use_chatbot2, {True: \"chatbot2\", False:\"chatbot1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from langchain_core.messages import AnyMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = init_chat_model(\"claude-sonnet-4-5-20250929\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define state\n",
    "class MessageState(BaseModel):\n",
    "    messages: Annotated[List[AnyMessage], add_messages]  # from langgraph.graph import MessagesState\n",
    "\n",
    "\n",
    "# define chatbot node\n",
    "def chatbot(state: MessageState):\n",
    "    reponse = llm.invoke(state.messages)\n",
    "    return {\"messages\": [reponse]}\n",
    "\n",
    "# create graph\n",
    "graph_builder = StateGraph(MessageState)\n",
    "\n",
    "# add nodes\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# add edges\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "# compile graph\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x00000279F79BA510>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize graph\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# run graph with invoke\n",
    "final_state = graph.invoke({\"messages\":[{\"role\":\"user\",\n",
    "                                         \"content\":\"Hello!\"\n",
    "                                         }]\n",
    "                            }) # can work with just [\"hello!\"] because we used predefined reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hello!', additional_kwargs={}, response_metadata={}, id='85b2d0a4-31e6-4416-ba87-bc08c6ddf91b'),\n",
       "  AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={'id': 'msg_01MnxVx6XqHbqMxU1s8MXdoW', 'model': 'claude-sonnet-4-5-20250929', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 9, 'output_tokens': 12, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-sonnet-4-5-20250929', 'model_provider': 'anthropic'}, id='lc_run--0598e82c-e399-4758-8db7-692d1aae9964-0', usage_metadata={'input_tokens': 9, 'output_tokens': 12, 'total_tokens': 21, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}})]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I help you today?'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run graph with stream\n",
    "final_state = graph.stream({\"messages\":[\"hello!\"]}, stream_mode=\"values\") # Emit all values in the state after each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Pregel.stream at 0x00000279F5D0E2D0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'messages': [HumanMessage(content='hello!', additional_kwargs={}, response_metadata={}, id='d7160a93-30cb-42e1-a544-7ae2aae302d1')]},\n",
       " {'messages': [HumanMessage(content='hello!', additional_kwargs={}, response_metadata={}, id='d7160a93-30cb-42e1-a544-7ae2aae302d1'),\n",
       "   AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={'id': 'msg_01MZF1zm8beHEjesvDozZuos', 'model': 'claude-sonnet-4-5-20250929', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 9, 'output_tokens': 12, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-sonnet-4-5-20250929', 'model_provider': 'anthropic'}, id='lc_run--c8d011fa-6ecc-45bf-b6a5-8940e346c314-0', usage_metadata={'input_tokens': 9, 'output_tokens': 12, 'total_tokens': 21, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}})]}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        message.pretty_print()\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hello!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "print_stream(final_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
